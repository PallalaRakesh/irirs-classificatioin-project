{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01ac197a-5db2-4f7c-b769-e8f41626788d",
   "metadata": {},
   "source": [
    "# IRIS-CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22abc786-0d0d-458f-a9c0-57b0d440faaa",
   "metadata": {},
   "source": [
    "## 1.setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5b582c9-a732-4e1a-9c8d-942b039b5657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0353b4d6-85d5-4065-8f73-aa4f8516de7c",
   "metadata": {},
   "source": [
    "## 2.prepare input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "895ffa77-3413-4b1c-999a-bea36902c3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Dataset Information from CSV ---\n",
      "Dataset shape: (150, 5)\n",
      "First 5 rows of the dataset:\n",
      "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n",
      "-----------------------------------\n",
      "\n",
      "--- Processed Data Dimensions ---\n",
      "Features (X) shape: (150, 4)\n",
      "Labels (y) shape: (150,)\n",
      "Target species names: ['setosa' 'versicolor' 'virginica']\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# iris = load_iris()\n",
    "# X = iris.data  # The feature data\n",
    "# y = iris.target # The target labels\n",
    "\n",
    "# print(\"--- Dataset Information ---\")\n",
    "# print(f\"Features (X) shape: {X.shape}\")\n",
    "# print(f\"Labels (y) shape: {y.shape}\")\n",
    "# print(f\"Target species names: {iris.target_names}\")\n",
    "# print(\"-\" * 25)\n",
    "\n",
    "# # We'll use 80% of the data for training and 20% for testing.\n",
    "# # The `random_state` ensures that the split is the same every time you run the code,\n",
    "# # making your results reproducible.\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42\n",
    "# )\n",
    "# print(\"\\nTrain Test Dimensions:\\n------------------------------------\")\n",
    "# print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# 1. Load the dataset from a CSV file\n",
    "# Make sure your 'iris.csv' file is in the same directory as this script.\n",
    "try:\n",
    "    iris_data = pd.read_csv(\"iris.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The file 'iris.csv' was not found.\")\n",
    "    print(\"Please ensure the file is in the same directory as this script.\")\n",
    "\n",
    "print(\"--- Dataset Information from CSV ---\")\n",
    "print(f\"Dataset shape: {iris_data.shape}\")\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(iris_data.head())\n",
    "print(\"-\" * 35)\n",
    "\n",
    "# 2. Prepare the data: separate features (X) and labels (y)\n",
    "# The last column is assumed to be the species label.\n",
    "# We use .iloc to select columns by their position.\n",
    "X = iris_data.iloc[:, :-1].values  # All rows, all columns except the last one\n",
    "y_raw = iris_data.iloc[:, -1].values # All rows, only the last column\n",
    "\n",
    "# Convert species names to numerical labels\n",
    "# We'll use pandas' factorize to assign a unique integer to each species name.\n",
    "# This is necessary because machine learning models work with numbers, not text.\n",
    "y, target_species_names = pd.factorize(y_raw)\n",
    "\n",
    "print(\"\\n--- Processed Data Dimensions ---\")\n",
    "print(f\"Features (X) shape: {X.shape}\")\n",
    "print(f\"Labels (y) shape: {y.shape}\")\n",
    "print(f\"Target species names: {target_species_names}\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "# 3. Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7539b4f-2412-4a45-b810-5297fddfdfaa",
   "metadata": {},
   "source": [
    "## 3.creating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a77e039-7484-48e4-add2-fdf73792b889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A pipeline simplifies the workflow by chaining together multiple steps.\n",
    "# Here, we combine a StandardScaler (for feature scaling) and a RandomForestClassifier.\n",
    "# The StandardScaler helps models that are sensitive to the scale of features.\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Preprocessing step\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42)) # Model step\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bb419d-4683-45b2-a96f-1f0d8ecdba39",
   "metadata": {},
   "source": [
    "## 4.training and evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f76b10b0-dcdb-4f69-8b5b-efe27561f888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete.\n",
      "-------------------------\n",
      "\n",
      "--- Model Evaluation ---\n",
      "Accuracy: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The .fit() method trains all steps in the pipeline.\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# The .predict() method applies the trained pipeline to the test features.\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# We use accuracy and a classification report to get a detailed view of the model's performance.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=iris.target_names)\n",
    "\n",
    "print(\"\\n--- Model Evaluation ---\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781d7551-9111-4377-9f56-0e3011251685",
   "metadata": {},
   "source": [
    "## 5.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "211a783e-0336-4243-a1fc-da6366b13433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Predicting a New Species ---\n",
      "New flower features: [5.1 3.5 1.4 0.2]\n",
      "Predicted species: setosa\n"
     ]
    }
   ],
   "source": [
    "# Let's say we have a new flower with these measurements:\n",
    "# [sepal_length, sepal_width, petal_length, petal_width]\n",
    "new_flower = np.array([[5.1, 3.5, 1.4, 0.2]]) # This is a Setosa\n",
    "\n",
    "# We use the trained pipeline to make a prediction on the new data.\n",
    "# The pipeline will automatically apply the StandardScaler before predicting.\n",
    "predicted_class = pipeline.predict(new_flower)\n",
    "predicted_species = iris.target_names[predicted_class][0]\n",
    "\n",
    "print(\"\\n--- Predicting a New Species ---\")\n",
    "print(f\"New flower features: {new_flower[0]}\")\n",
    "print(f\"Predicted species: {predicted_species}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3c47e1-a5d6-4c9d-855c-79d10257661f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
